\documentclass{article}
\usepackage{graphicx}
\usepackage{natbib}
\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=red,
    filecolor=magenta,
    urlcolor=purple,
    citecolor=violet
}


\usepackage[dvipsnames]{xcolor}
\colorlet{LightRubineRed}{RubineRed!100}
\definecolor{mypink2}{RGB}{219, 48, 122}

\title{Guide 1: Obtaining State Weather Station Data}
\author{Marc Los Huertos}
\date{\today~(ver. 0.91)} 

\begin{document}
\maketitle

\section{Introduction}

\subsection{Goals}

Using a list of active weather stations in the United States, you  will download the data from five stations and write weather station data csv files. 

\subsection{Selected History of Climate Science}

Geologists have known the climate has been changing over the Earth's history. But what causes these changes has been a major research area for over 100 years. There are numerous drivers that contribute to changing climates -- including the arrangement of the continents on the planet, the distance to the sun, energy generated by the sun, volanic activity, and the composition of the Earth's atmosphere. 

It's the last one that we'll spend time because the Earth's temperature are changing pretty dramatically over the last 100 years and the cause is no mystery -- the human activity that has released carbon dioxide (CO$_2$) into the atmosphere. The two main sources of CO$_2$ is from land use change, e.g. deforestration, and the burning of fossil fuels, e.g. coal, oil, and natural gas. 

The first person to propose the role of CO$_2$ on the Earth's atmosphere was a Swedish scientist Svante Arrhenius, who figured out that CO$_2$ absorbs infarred light \citep{rodhe1997svante}. Moreover, he deduced that the Earth's temperature was actually warmer than it might otherwise be if CO$_2$ was not part of the Earth's atmosphere. 

\subsection{Why Look at Individual Stations?}

I don't think there is a single, perfect way to analyze and communicate climate change. But the beauty of the network of stations in the USA and around the world is that these stations record weather as expecienced by local people. And while indiviudual stations may not represent the overall regional and global patterns well, this give us a mechanism to connect local experiences to regional or global processes. 

Of course, some may fixate on the local pattern and remain unconvinced of the larger context and for those folks, there may be better ways to communicated climate data. 

However, I would be remiss in failing to mention that some may fixate on local patterns and use these patterns to ignore or to dimiss the patterns in other regions. 

Finally, the impacts of climate change are highly specific to the region in question. Thus, once someone understands the impacts on climate change in their region, they my not be able to appreciate how differnet the climate impacts might affect other peoples, who maybe more vulneratble, around the globe. 

Thus, with these weaknesses in mind, I will pursue this project with an eye to address these other issues at later stages.

\subsection{Approach}

\subsubsection{NOAA Data Records}

The US National Oceanic and Atmospheric Administration (NOAA) maintains several sources of digital weather data from the USA and beyond. These data have been collected from stations around the country to support a wide range of human activities that include farming, aviation, shipping, and even armed conflict. 

At various times, these records have been used to evaluate long-term climate change with varying success. Without a doubt, these data are not perfect, but they remain that foundation of an effective adn professionally maintained environmental monitoring program that engenders integrity, even when facing budget cuts. 

I will use these data to select for a station with a long record for each state in the USA. Future projects might evaluate the record for stations around the world, but we will see about that. 

\subsubsection{R Programming Language}

R is an open source programming environment that has become one of the most popular tools for statisticians and data scientists. Capitalizing on the open source framework, a wide range of libraries or packages have been developed to facilitate data processing, analysis, and graphical displays. 

%For the project we'll use a few packages that need to be installed and loaded. Using the lower right panel, you can install the packages by clicking on the "Packages" tab and then "Install" and then type in the package name and click "Install".

\subsection{Revised Document Structure}

Based on some feedback in the last week, I have re-orgnaized the document with bullets of the steps and then the code. In the following sections, I'll descriptions about ``what the code does and why". But several folks see the text and get tuned out.

There are two weaknesses with this approach that I can see. First, if the code does not work, you will have a really hard time figuring out why, since you have no idea what the code is supposed to do. Second, if the code works, you will not really be learning any R coding. Just how to copy and paste.

I have created a bunch of functions, which can then be used to collect Let's try this and see how it works! 

\subsection{Preparing R for the Project}

I suggest you do the following to prepare: 

\begin{enumerate}
  \item Create a folder for the project, I suggest ``Regional\_Climate\_Trends''. Note that there are no spaces in the folder name. 
  \item Next create a new R markdown file to write your code. Name and save it in your project folder. (For details see Section~\ref{subsec:RMarkdown})
  \item Download the file oldest.activestation.csv from the Canvas page and upload it to the directory you created in the previous step.
  \item Download the file called Guide1functions.R from the Canvas page and upload it to the directory you created in the previous step. 
  \item Open the file in Rstudio and run the code, using the ``source'' action item near the top, right of the editor window.
\end{enumerate}

\section{R Functions for Getting Weather Station Data}

\subsection{Marc's Custom Functions: Guide1functions.R}

<<setup, echo=FALSE, results='hide', message=FALSE>>=
library(here)
source(here("04_Regional_Climate_Trends", "Guides", "Guide1functions.R"))
@

These functions are designed so you don't have to type all the code! But check to see if they work for you, because they can (apparently) break really easily. 

From the Canvas page, go to the \href{https://github.com/marclos/RTricks/blob/master/04_Regional_Climate_Trends/Guides/Guide1functions.R}{Guide1functions.R} code and download the file to your computer. Then upload the file to a directory in Rstudio. I suggest you create a new directory called ``Regional\_Climate\_Trends'' and then upload the file to that directory. Please note, avoid spaces in your directory names.

Open the file in Rstudio and run the code, using the ``source'' action item near the top, right of the editor window (Figure~\ref{fig:source_code}).

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{figure/Guide1Source.png}
\caption{The "source" action item is located in the upper right of the editor window. This will run the entire code with all the functions into the R environment.}
\label{fig:source_code}
\end{figure}

The function have been written to the R Environment and you can close Guide1.functions.R file. We don't need any more. However, if you'd like to see the functions, I have been written out in this document. 

\subsection{Creating a Record of Your Commands}

Use the Rmd file to record your R code and comments. This will help you remember what you did and why. See MarcsTemplate.Rmd as a skeleton file. 

\subsection{Function Descriptions and Use}

The following functions are used to select the weather stations, download data, and write weather station data csv files.

\begin{description}

\item[Subset Inventory Data with my.state]  The inventory data is a list of all the weather stations in the USA, US Territories, and Canada. This function will subset the data to only include the stations in the state of interest.

\begin{center}
\textbf{Function: \textcolor{Plum}{readInventory.fun()}}
\end{center}

This function requires two parameters to be set: filename and my.state. See Section~\ref{subsec:readInventory} for more details.

I suggest you use file.choose() and assign filename.csv to the path and name of the csv file in your project directory.  

Example of how to use the function:

<<echo=TRUE, eval=TRUE>>=
my.state <- "CA"
filename.csv <- "/home/mwl04747/RTricks/04_Regional_Climate_Trends/Data/SP24/stations.active.oldest.csv"
my.inventory <- readInventory.fun(filename.csv, my.state)
@

Creates a dataframe called my.inventory that contains the inventory data for the state/territory of interest. You should see that in the R environment. Note: The file name is cut off because my path is too long!

\item[Download and Read Selected Weather Station Data into R] This function will download the weather station data from the NOAA website and read it into R.

\begin{center}
\textbf{Function: \textcolor{Plum}{downloadStations.fun()}}
\end{center}

This functions requires two parameters: data path and name of inventory dataframe (my.inventory). The data path is a folder that you can always get your station data from if you need it. For example, if you need to update the data, you can just download the data from the NOAA website and then read it into R. For more information on this function see Section~\ref{subsec:downloadStations}.

The path to your data folder will be different, I created a directory to separate my data by class year, you don't need that! But it is nice to keep the data in a separate folder so things don't get to hectic.

An example of how to use the function: 

<<echo=TRUE, eval=TRUE, results='hide'>>=
datapath = "/home/mwl04747/RTricks/04_Regional_Climate_Trends/Data/SP24/"
downloadStations.fun(datapath, my.inventory)
@ 

This will download the data from the NOAA website and read it into R then written as compresseed gz and uncompressed czv files in your data folder. Check to see that you have both csv.gz and .csv files in your data folder.

\end{description}

\noindent {\Large\textcolor{LightRubineRed}{You're are done with this guide, go to Guide 2!}}

\section{Explaining the Process and Code}

\subsection{Working with a R Markdown File}\label{subsec:RMarkdown}

To record your history of R code, I suggest use an Rmarkdown file to keep your code handy. 

To do this open a new file and select R Markdown -- Define a title, author, and output format as PDF. Then save the file (Figure~\ref{fig:RMarkdown}). 

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{/home/mwl04747/RTricks/04_Regional_Climate_Trends/Guides/figure/Guide1NewRMarkdown.png}
\caption{Creating a new R Markdown file.}
\label{fig:RMarkdown}
\end{figure}


Then save the file in your project folder and knit the file to create a PDF. Look at the PDF to see how various parts of the Rmd file were knitted. Notice that there are generally two sections: text and R chunks. As you write th R code, you will can record your code in the R chunks AND develop the output into a document for future reference.

Look carefully at the Rmd file and take note of the following: First, there are chunks of R code separated from the text by a line of three backticks. Second, the R code is written in the chunks and the output is written below the code. Finally, there is a set of backticks at the end of the code chunk. This section is gray and is where you can record your Rcode. I suggest you delete existing the one line of R code inside the existing template chuck.  

\subsubsection{R Environment and knitr}

When you knit, R starts a new environment and runs the code in the chunks. But that means the new environment doesn't have the data you have created in your current environment. So, I suggest you use the R markdown to double check that everything is working well. 

I have created an R Markdown file for you to use. It is called MarcsTemplate.Rmd. As a template, you can use and change the code as you go. 

\section{Function Descriptions}

\subsection{readInventory.fun}\label{subsec:readInventory}

Here's the function:

<<show_readInventory.fun, echo=FALSE>>=
print(readInventory.fun)
@

\subsection{downloadStations.fun}\label{subsec:downloadStations}

Here's the function:

<<show_downloadStation.fun, echo=FALSE>>=
print(downloadStations.fun)
@

\section{Trouble Shooting and Workarounds}

I will be getting all the guides working before working on this! But if there are errors with the custom function, this is where workarounds will be described! Please Slack me and mentors if you have any problems!

%\subsubsection{Identify List of State IDs (FIPS)}

%Using the rNOAA library in R, we can query NOAA's database to identify station codes (FIPS) by state. With the states and some territories, there are 55 FIPS for US weather stations. Althogh these include the District of Columbia, they do not include US Territories, sich as Guam, Puerto Rico, Marshall Islands, etc. We'll have to use a different search code for these.

%rNOAA has a simple function to list for each of the states and the weather stations in each. I use ncdc\_locs() functions to select each state and ncdc\_station() to obtain the station ids with the longest records. 

%The function queries the NOAA website and retrieves state codes, ``FIPS:XX''. Each state has a number of weather stations,\footnote{Project Idea: It would be nice to make a map of how concentrated the stations spatially.} some with a long record, some with a short record, and some with numerous interruptions. Our goal is to select a long record with few missing data. 

%\subsubsection{Selection Stations}

%With the state ids, we can evaluate the metadata for all the weather stations, which will work to get the longest records, using \texttt{ncdc\_stations()}. 

%First, we subset the data for stations that actively collecting data. Then we'll sort to the active stations to find the one with the longest records. We will use these stations for our analysis. 

%There were some records that didn't have robust TMAX/TMIN records, so there are some states that I had to manually select an alternative stations. 

\subsection{Defining Path \& Read Data}

First, we install some packages and read in the data. I suggest you create a folder for the project (I created one called ``04\_Regional\_Climate\_Trends") and then used the function here() to get the working directory and read the csv into R. This might be easier than the file.choose() option, but you can use that if you prefer.

The first option: 

Use this code to select the file from the console:

\begin{verbatim}
> file.choose()
\end{verbatim}

Then paste the result in the Rmd file to track the results to define the file name:

<<>>=
filename = "home/mwl04747/RTricks/04_Regional_Climate_Trends/Data/SP24/stations.active.oldest.csv"


# OR what I use! 
library(here)
filename = read.csv(
  here("04_Regional_Climate_Trends", "Data", "SP24", "stations.active.oldest.csv"))

@ 

\subsection{NA.csv as a duplicate?}

I am not sure why, but in the downloadStations.fun(), the file is saved as NA.csv. I have no idea why. If you find this, let me know, I'd like to figure out if their is a bug in the code creating this csv.

%suggest you change the name of the file to something more descriptive.

\subsection{Download gz files with folder concantentated names}

I don't know what causes this problem yet. But 5 students had this issue on Wedesday, but no one on Tuesday. That less than half the students had this issue is perplexing and I am continuing to work on this. More soon, I hope. 

\section{Text that needs to be editted}

\subsection{Selecting Weather Records by State}

There are numerous ways to analyze temperature records, where stations can be analyzed individually or records could be sampled and analyzed in spatially in grids. Each of these are valid approaches depending on the question to be addressed. 

Here are the questions we will address: 

\begin{itemize}
  \item What stations have the longest meterological records in the USA?
  \item Can we determine the reliability of these stations?
  \item Finally, is there a temperature trend?
\end{itemize}

\subsection{Map US Weather Stations}

Here's a map of the weather stations in the dataset. Pretty lame map!  We'll make a better one later.\footnote{Evelyn/Brody: This is a good change to see how to use R for map making! First we need to transform that data.}

<<>>=
plot(stations.active.oldest$LONGITUDE, 
     stations.active.oldest$LATITUDE, 
     xlab = "Longitude",ylab = "Latitude", 
     pch=20, cex=0.3, col='gray60', las=1,
     main = "US Weather Stations")
@
\subsection{Select and Evaluate State Data}

<<>>=
stations.unique = 
  unique(stations.active.oldest[,c("STATE", "STATE_NAME")])

xtab = xtable(stations.unique)
@

The each of you will select a state -- see the Google Sheet sign up so we have a diverse set of states.

<<>>=
my.state = "CA" # change the "CA" to your state
@

\section{Download Data from NOAA}

\subsection{Subset Station Data by State}

This uses the stations.active.oldest file to download the data from the NOAA website based on the state you have choose.

The URL for the data is: \url{https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00023230/detail}.

<<>>=# Select Stations in State
my.stations = subset(stations.active.oldest, STATE == my.state)

# Download Updated Station Data
i=1
here::here("04_Regional_Climate_Trends", my.stations$ID[i])
@


% bibilography section here-------------------------------------------
%\clearpage

\bibliographystyle{apalike}
%\renewcommand\bibname{References}{}
\bibliography{/home/mwl04747/RTricks/references}%	\addcontentsline{toc}{chapter}{References}


\end{document}
